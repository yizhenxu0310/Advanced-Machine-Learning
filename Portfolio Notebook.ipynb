{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: https://github.com/yizhenxu0310/Advanced-Machine-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Yizhen Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Michael D. Parrott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: https://github.com/yizhenxu0310/Advanced-Machine-Learning/tree/master/assignment%20%231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Description: This project is to explore U.N. World Happiness Data to predict the happiness level. The overall architecture is as follows. First, use visualization to explore bivariate results. Second, do feature selection. Third, run prediction models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data: U.N. World Happiness Data.There are 156 observations in total. There are 8 variables, including Happiness_level, country or region, GDP per capita, Social support, Healthy life expectancy, Freedom to make life choices, Generosity, Perception of curruption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature selection: Use SelectKBest and Chi to do feature selection. And the result shows that the five best features are region, GDP per capita,  Healthy life expectancy, Social support and Perceptions of corruption. So in all our predictive model, these five variables are independent variables, and Happiness_level is the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model: There are two predictive models used, KNN and Random Forest, to use 5 features to predict happiness level. First, KNN. After GridSearchCV, the best parameter is n_neighbors of 5. Using this parameter, the model turns out that best mean cross-validation score is 0.547 and test-set score is 0.359. Second, Random Forest. After GridSearchCV, the best parameter is max_depth of 8. Using this parameter, the model turns out that best mean cross-validation score is 0.530 and test-set score is 0.359."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: https://github.com/yizhenxu0310/Advanced-Machine-Learning/tree/master/assignment%20%232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Description: This project is to make use of brain tumor diagnostic MRI image data to predict whether the patient will be diagnosed as have tumor or not. The overall architecture is as follows. First, Visualize brain tumor images. Second, run prediction models with one transferring model. Third, submit my best model to leaderboard. Fourth, import the best model from the leaderboard, compare it with mine and then fit it to my training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data: brain tumor diagnostic MRI image data.There are 253 in total. Data preprocessing is important in this project. For X data, First, import image, make sure it's RGB and resize to height and width of 224. Second, do min max transformation. Third, Create final shape as array with correct dimensions for Keras. After completion of preprocessing, the shape of X is (253, 224, 224, 3). For Y label, First, use Repeat function to create 155 'yes' and 98 'no'. Second, use Get_dummies function to transfer them to 1 and 0. After completion of preprocessing, the shape of y is (253, 2) with one column meaning yes and one column meaning no. Finally, do training and testing data split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model: There are three Nerual Network predictive models used to predict whether it has tumor or not. All the model's last layer's hidden notes is 2. First, Neural Network with 4 hidden layers with every layer of Conv2D and Maxpooling2D, optimizer=\"adam\", loss= 'categorical_crossentropy', epochs = 5 and verbose=1. Second, Neural Network with 43 hidden layers with every layer of Conv2D and Maxpooling2D, optimizer=\"adam\", loss= 'categorical_crossentropy', epochs = 5 and verbose=1, and callback. The callback is set to ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1). Third, transferring model. The base model is InceptionResNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet') and then add GlobalAveragePooling2D() to base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: https://github.com/yizhenxu0310/Advanced-Machine-Learning/tree/master/assignment%20%233"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Description: This project is to make use of BBC text classification data to predict the category that a text belongs to. The overall architecture is as follows. First, Visualize target variables. Second, preprocess the data such that each document in the data is represented as a sequence of equal length. Third, fit 7 prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data: BBC text data.There are 2225 observations in total. There are 2 columns, text and category. More specifaically, there are 5 categories, including tech, business, sport, entertainment and politics. Sport and business categories appear most while entertainment category appears least. Data preprocessing is important in this project. First, cut reviews after 100 words and only consider the top 10,000 words in the dataset. Second, tokenize the word. Third, do pad_sequence to X and asarray to y. Fourth, do the training and testing data split. After the completion of preproccessing, Shape of text tensor is (2225, 100), Shape of category tensor is (2225,), Shape of X_train (1668, 100), Shape of X_test (557, 100), Shape of y_train (1668,), Shape of y_test (557,)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model: There are 6 models in total. And model B performs the best. \n",
    "\n",
    "\n",
    "  A. A model with an embedding layer and dense layers (but w/ no layers meant for sequential data)\n",
    "\n",
    "  B. A model using an Embedding layer with Conv1d Layers\n",
    "\n",
    "  C. A model using an Embedding layer with one sequential layer (LSTM or GRU)\n",
    "\n",
    "  D. A model using an Embedding layer with stacked sequential layers (LSTM or GRU)\n",
    "\n",
    "  E. A model using an Embedding layer with bidirectional sequential layers\n",
    "\n",
    "  F. Now retrain your best model from C, D, and E using dropout "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
