{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j35k2viqgA_u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnKiBWlpg80l"
   },
   "source": [
    "**1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_J0E43WDhC9f"
   },
   "source": [
    "#### There are 2225 observations in total in this dataset.It has two columns, category and text. Text is the content of that observation, and category is the type of the text. There are five categories, including tech, business, sport, entertainment and politics. Sport and business categories appear most while entertainment category appears lease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "mmHA9TXLgRWQ",
    "outputId": "d4d192a4-cb66-4fcd-c86f-6ddba594bb5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "...             ...                                                ...\n",
       "2220       business  cars pull down us retail figures us retail sal...\n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
       "2223       politics  how political squabbles snowball it s become c...\n",
       "2224          sport  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fe0mTZ4gTsJ"
   },
   "outputs": [],
   "source": [
    "group=df.groupby(\"category\").count()\n",
    "label = group.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "7U-G8q7RgWZK",
    "outputId": "601fada9-cb4c-4d33-f3d2-27c87e862aa5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "y_pos = np.arange(len(label))\n",
    "y_value = group.text.tolist()\n",
    "\n",
    "plt.bar(y_pos.tolist(), y_value)\n",
    "for i, v in enumerate(y_value):\n",
    "    ax.text(i-0.1,v+10, str(v), color='blue', fontweight='bold')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.xticks(y_pos, label)\n",
    "plt.box(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2AdaMjChIlf"
   },
   "source": [
    "**2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "oOhwtUm8gcZ8",
    "outputId": "fc2f55b0-af9a-45c4-ee56-1a077de332c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29726 unique tokens.\n",
      "Shape of text tensor: (2225, 100)\n",
      "Shape of category tensor: (2225,)\n",
      "Shape of X_train (1668, 100)\n",
      "Shape of X_test (557, 100)\n",
      "Shape of y_train (1668,)\n",
      "Shape of y_test (557,)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data into one hot vectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x = df['text']\n",
    "y = df['category']\n",
    "maxlen = 100  # We will cut reviews after 100 words\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x) \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "y = np.asarray(y)\n",
    "\n",
    "print('Shape of text tensor:', x.shape)\n",
    "print('Shape of category tensor:', y.shape)\n",
    "\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=12)\n",
    "print('Shape of X_train', x_train.shape)\n",
    "print('Shape of X_test', x_test.shape)\n",
    "print('Shape of y_train', y_train.shape)\n",
    "print('Shape of y_test', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5l4I1arhonF"
   },
   "source": [
    "**3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gH5Ntuq8h8D5"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7HKpRnnh3t4"
   },
   "source": [
    "Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "colab_type": "code",
    "id": "A_q3U7Cfh7SE",
    "outputId": "7d43e452-853e-4ca3-d8f1-310b61751aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 16005     \n",
      "=================================================================\n",
      "Total params: 336,005\n",
      "Trainable params: 336,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 0s 165us/step - loss: 1.5923 - acc: 0.2944\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 0s 132us/step - loss: 1.4061 - acc: 0.7422\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 0s 134us/step - loss: 1.0732 - acc: 0.8993\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 0s 129us/step - loss: 0.6706 - acc: 0.9718\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 0s 134us/step - loss: 0.3629 - acc: 0.9886\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 0s 133us/step - loss: 0.1808 - acc: 0.9946\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 0s 133us/step - loss: 0.0855 - acc: 0.9988\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 0s 137us/step - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1668/1668 [==============================] - 0s 131us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 0s 131us/step - loss: 0.0062 - acc: 1.0000\n",
      "557/557 [==============================] - 0s 60us/step\n",
      "Test loss, Test acc: [0.326812760085135, 0.9048473834991455]\n"
     ]
    }
   ],
   "source": [
    "#model A\n",
    "modelA = Sequential()\n",
    "modelA.add(Embedding(max_words, 32, input_length=maxlen))\n",
    "modelA.add(Flatten())\n",
    "modelA.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# complie model\n",
    "modelA.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "modelA.summary()\n",
    "\n",
    "# fit model\n",
    "modelA.fit(x_train, pd.get_dummies(y_train), epochs=10, batch_size=32)\n",
    "\n",
    "#evaluate model\n",
    "evaluationA=modelA.evaluate(x_test, pd.get_dummies(y_test))\n",
    "print('Test loss, Test acc:', evaluationA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJR85OOUj2Me"
   },
   "source": [
    "Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "colab_type": "code",
    "id": "Ks5DMVwgj3l_",
    "outputId": "eae47640-374d-416c-da7c-895249d23a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 91, 64)            20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 340,869\n",
      "Trainable params: 340,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 1s 593us/step - loss: 1.5901 - acc: 0.2710\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 1s 517us/step - loss: 1.4880 - acc: 0.4472\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 1s 512us/step - loss: 1.3007 - acc: 0.5066\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 1s 538us/step - loss: 1.0446 - acc: 0.7254\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 1s 509us/step - loss: 0.7464 - acc: 0.8795\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 1s 519us/step - loss: 0.4818 - acc: 0.9299\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 1s 515us/step - loss: 0.2869 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 1s 506us/step - loss: 0.1635 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1668/1668 [==============================] - 1s 526us/step - loss: 0.0895 - acc: 0.9934\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 1s 507us/step - loss: 0.0465 - acc: 0.9994\n",
      "557/557 [==============================] - 0s 159us/step\n",
      "Test loss, Test acc: [0.2939521175419621, 0.9102333784103394]\n"
     ]
    }
   ],
   "source": [
    "# Model B\n",
    "modelB = Sequential()\n",
    "modelB.add(Embedding(max_words, 32, input_length=maxlen))\n",
    "modelB.add(layers.Conv1D(64, 10, activation='relu')) \n",
    "modelB.add(layers.GlobalMaxPooling1D())\n",
    "modelB.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "modelB.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "modelB.summary()\n",
    "\n",
    "# fit model\n",
    "modelB.fit(x_train, pd.get_dummies(y_train), epochs=10, batch_size=32)\n",
    "\n",
    "# evaluate model\n",
    "evaluationB = modelB.evaluate(x_test, pd.get_dummies(y_test))\n",
    "print('Test loss, Test acc:', evaluationB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNSK12polwux"
   },
   "source": [
    "Model C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "colab_type": "code",
    "id": "FTFUQRAFlyH-",
    "outputId": "8411d76c-8640-472f-e828-f19ae797a96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 328,485\n",
      "Trainable params: 328,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 1.5195 - acc: 0.3351\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 1.1286 - acc: 0.4856\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.9166 - acc: 0.6511\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.8080 - acc: 0.7566\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.6871 - acc: 0.8219\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.5359 - acc: 0.8945\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.3916 - acc: 0.9275\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.2540 - acc: 0.9652\n",
      "Epoch 9/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.2123 - acc: 0.9532\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 3s 2ms/step - loss: 0.1757 - acc: 0.9586\n",
      "557/557 [==============================] - 0s 349us/step\n",
      "Test loss, Test acc: [0.6053964950451945, 0.8222621083259583]\n"
     ]
    }
   ],
   "source": [
    "# Model C\n",
    "modelC = Sequential()\n",
    "modelC.add(Embedding(max_words, 32, input_length=maxlen))\n",
    "modelC.add(layers.LSTM(32))\n",
    "modelC.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# complie model\n",
    "modelC.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "modelC.summary()\n",
    "\n",
    "# fit model\n",
    "modelC.fit(x_train, pd.get_dummies(y_train), epochs=10, batch_size=32)\n",
    "\n",
    "# evaluate model\n",
    "evaluationC = modelC.evaluate(x_test, pd.get_dummies(y_test))\n",
    "print('Test loss, Test acc:', evaluationC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgSJ83uOms5V"
   },
   "source": [
    "Model D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "uAB6dh-tmvpK",
    "outputId": "42308bdc-0a35-4fe4-ab17-b4018245e32d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100, 32)           8320      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 32)           8320      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 345,125\n",
      "Trainable params: 345,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 8s 5ms/step - loss: 1.4441 - acc: 0.3135\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 1.0796 - acc: 0.4712\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.8597 - acc: 0.6331\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.6736 - acc: 0.7332\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.5530 - acc: 0.8022\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.4064 - acc: 0.8627\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.3013 - acc: 0.9083\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.2120 - acc: 0.9305\n",
      "Epoch 9/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.1586 - acc: 0.9556\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 7s 4ms/step - loss: 0.1218 - acc: 0.9682\n",
      "557/557 [==============================] - 1s 992us/step\n",
      "Test loss, Test acc: [0.7868595275780457, 0.7845601439476013]\n"
     ]
    }
   ],
   "source": [
    "# Model D\n",
    "modelD = Sequential()\n",
    "modelD.add(Embedding(max_words, 32, input_length=maxlen))\n",
    "modelD.add(layers.LSTM(32, return_sequences=True))\n",
    "modelD.add(layers.LSTM(32, return_sequences=True))\n",
    "modelD.add(layers.LSTM(32))\n",
    "modelD.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "modelD.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "modelD.summary()\n",
    "\n",
    "# fit model\n",
    "modelD.fit(x_train, pd.get_dummies(y_train), epochs=10, batch_size=32)\n",
    "\n",
    "# evaluate model\n",
    "evaluationD = modelD.evaluate(x_test, pd.get_dummies(y_test))\n",
    "print('Test loss, Test acc:', evaluationD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxJo3pXynPuV"
   },
   "source": [
    "Model E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "colab_type": "code",
    "id": "R6THRdNkhp-B",
    "outputId": "186ae7e4-9f27-4171-b4d8-41f96bc560a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 336,965\n",
      "Trainable params: 336,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 1.5754 - acc: 0.2782\n",
      "Epoch 2/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 1.0704 - acc: 0.5713\n",
      "Epoch 3/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.6771 - acc: 0.7458\n",
      "Epoch 4/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.4872 - acc: 0.8070\n",
      "Epoch 5/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.3885 - acc: 0.8543\n",
      "Epoch 6/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.3408 - acc: 0.8687\n",
      "Epoch 7/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.3170 - acc: 0.8939\n",
      "Epoch 8/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.2390 - acc: 0.9388\n",
      "Epoch 9/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.1732 - acc: 0.9574\n",
      "Epoch 10/10\n",
      "1668/1668 [==============================] - 4s 2ms/step - loss: 0.1314 - acc: 0.9658\n",
      "557/557 [==============================] - 0s 591us/step\n",
      "Test loss, Test acc: [0.6711077909495287, 0.8438060879707336]\n"
     ]
    }
   ],
   "source": [
    "# Model E\n",
    "modelE = Sequential()\n",
    "modelE.add(Embedding(max_words, 32, input_length=maxlen))\n",
    "modelE.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "modelE.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "modelE.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "modelE.summary()\n",
    "\n",
    "# fit model\n",
    "modelE.fit(x_train, pd.get_dummies(y_train), epochs=10, batch_size=32)\n",
    "\n",
    "# evaluate model\n",
    "evaluationE = modelE.evaluate(x_test, pd.get_dummies(y_test))\n",
    "print('Test loss, Test acc:', evaluationE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgFF9XNnnqZm"
   },
   "source": [
    "Model F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "SQtyzzPznrjj",
    "outputId": "e3a1b51f-4cc3-4a79-834d-1c3423fbbd31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 100, 32)           320000    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 336,965\n",
      "Trainable params: 336,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1668/1668 [==============================] - 5s 3ms/step - loss: 1.5915 - acc: 0.2608\n",
      "Epoch 2/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 1.3750 - acc: 0.4592\n",
      "Epoch 3/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 1.2112 - acc: 0.5240\n",
      "Epoch 4/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 1.0911 - acc: 0.5647\n",
      "Epoch 5/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 1.0424 - acc: 0.5863\n",
      "Epoch 6/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 1.0371 - acc: 0.5977\n",
      "Epoch 7/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.9845 - acc: 0.6427\n",
      "Epoch 8/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.9073 - acc: 0.6978\n",
      "Epoch 9/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.7580 - acc: 0.7584\n",
      "Epoch 10/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.6339 - acc: 0.8064\n",
      "Epoch 11/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.5158 - acc: 0.8495\n",
      "Epoch 12/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.4009 - acc: 0.8951\n",
      "Epoch 13/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.3389 - acc: 0.9053\n",
      "Epoch 14/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.2599 - acc: 0.9203\n",
      "Epoch 15/15\n",
      "1668/1668 [==============================] - 4s 3ms/step - loss: 0.2221 - acc: 0.9347\n",
      "557/557 [==============================] - 0s 664us/step\n",
      "Test loss, Test acc: [0.45079569745962667, 0.8563734292984009]\n"
     ]
    }
   ],
   "source": [
    "# Model F\n",
    "modelF = Sequential()\n",
    "modelF.add(Embedding(max_words, 32, input_length=maxlen))\n",
    "modelF.add(layers.Bidirectional(layers.LSTM(32, dropout=0.3, recurrent_dropout=0.3))) \n",
    "modelF.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "modelF.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "modelF.summary()\n",
    "\n",
    "# fit model\n",
    "modelF.fit(x_train, pd.get_dummies(y_train), epochs=15, batch_size=32)\n",
    "\n",
    "# evaluate model\n",
    "evaluationF = modelF.evaluate(x_test, pd.get_dummies(y_test))\n",
    "print('Test loss, Test acc:', evaluationF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgSUZGajoysE"
   },
   "source": [
    "**4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "y0TXs5jTqE1H",
    "outputId": "5c90f5f2-1f3a-494e-8d7f-d44d5d02c334"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.910233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.904847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.856373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.843806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.822262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.784560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test acc\n",
       "model          \n",
       "B      0.910233\n",
       "A      0.904847\n",
       "F      0.856373\n",
       "E      0.843806\n",
       "C      0.822262\n",
       "D      0.784560"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={'model': ['A','B','C','D','E','F'], 'test acc': [evaluationA[1], evaluationB[1],evaluationC[1],evaluationD[1],evaluationE[1],evaluationF[1]]}\n",
    "df2=pd.DataFrame(data=d)\n",
    "df2.set_index([\"model\"], inplace=True)\n",
    "df2.sort_values(by=\"test acc\" , ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)Model B using an Embedding layer with Conv1d Layers performs the best.\n",
    "#### (2)And I think I might improve the model in following ways. First, use Glove embedding matrix weights. For those words which are not in the matrix would be set to 0. Second, add layers. For now, basically what I did is to use only two hidden layers. I might increase it to 3 or 4 layers. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AML_HW3_Yizhen Xu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
